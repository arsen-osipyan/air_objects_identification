{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322b01a5-63f4-42f2-bfb7-b34b62a4006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843b25ce-0191-45a8-b946-f84e9adcd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files_from_dir(dir):\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        f = os.path.join(dir, file)\n",
    "        if os.path.isfile(f) and f.endswith('.csv'):\n",
    "            files.append(f)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb7ac10-74c8-4026-8bab-f1c2e8cea57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cp_data(data, error=False, velocity=False, acceleration=False):\n",
    "    data = data.sort_values(by=['rs_id', 'id', 'time']).reset_index(drop=True)\n",
    "    data = data.drop(columns=['load_time'])\n",
    "\n",
    "    if not error:\n",
    "        data = data.drop(columns=[f'{axis}_err' for axis in ('x', 'y', 'z')])\n",
    "\n",
    "    if not velocity:\n",
    "        data = data.drop(columns=[f'v_{axis}_est' for axis in ('x', 'y', 'z')])\n",
    "\n",
    "    if not acceleration:\n",
    "        data = data.drop(columns=[f'a_{axis}_est' for axis in ('x', 'y', 'z')])\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bba52a-c458-4996-ac9e-947d641d4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_cp_data(data):\n",
    "    return data.groupby(by=['rs_id', 'id'])['time'].describe()[['count', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064e04a7-cb4e-413f-9b77-352e5d9971e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track(data, rs_id, id):\n",
    "    return data[(data['rs_id'] == rs_id) & (data['id'] == id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764a7870-5af0-45d6-80ff-7614dead328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_timeranges_intersection(track_1, track_2):\n",
    "    t_min_1, t_max_1 = track_1['time'].min(), track_1['time'].max()\n",
    "    t_min_2, t_max_2 = track_2['time'].min(), track_2['time'].max()\n",
    "\n",
    "    t_min, t_max = max(t_min_1, t_min_2), min(t_max_1, t_max_2)\n",
    "    return t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f048fe8-cdc4-4250-b1f4-a0ef6a928ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tracks(track_1, track_2, track_length, error, velocity, acceleration):\n",
    "    t_min, t_max = get_tracks_timeranges_intersection(track_1, track_2)\n",
    "\n",
    "    # dt_1_mean = track_1['time'].diff().mean()\n",
    "    # dt_2_mean = track_2['time'].diff().mean()\n",
    "    # dt = max(dt_1_mean, dt_2_mean)\n",
    "    # t_min, t_max = t_min - int(dt/2), t_max + int(dt/2)\n",
    "    \n",
    "    if t_min >= t_max:\n",
    "        return None\n",
    "\n",
    "    t_mid = t_min + int(0.5 * (t_max - t_min))\n",
    "\n",
    "    track = pd.concat([track_1, track_2])\n",
    "\n",
    "    if len(track) < track_length:\n",
    "        return None\n",
    "                    \n",
    "    track['dt_mid'] = np.abs(track['time'] - t_mid)\n",
    "    track = track.sort_values(by=['dt_mid']).head(track_length)\n",
    "    \n",
    "    if len(track['id'].unique()) == 1:\n",
    "        return None\n",
    "    \n",
    "    track = track.sort_values(by=['time']).reset_index(drop=True)\n",
    "    track = track[\n",
    "        ['time', 'x', 'y', 'z'] + \\\n",
    "        (['x_err', 'y_err', 'z_err'] if error else []) + \\\n",
    "        (['v_x_est', 'v_y_est', 'v_z_est'] if velocity else []) + \\\n",
    "        (['a_x_est', 'a_y_est', 'a_z_est'] if acceleration else [])\n",
    "    ]\n",
    "    \n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef8ca1d-322c-4952-b8a4-cbbac4fc4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tl_data_from_cp_data_file(file, track_length, error, velocity, acceleration):\n",
    "    row_length = 4 + int(error) * 3 + int(velocity) * 3 + int(acceleration) * 3\n",
    "    x, y = torch.empty((0, track_length * row_length)), torch.empty((0, 1))\n",
    "    cp_data = pd.read_csv(file)\n",
    "\n",
    "    cp_data = transform_cp_data(cp_data, error, velocity, acceleration)\n",
    "    \n",
    "    tracks = [(rs_id, id) for rs_id in cp_data['rs_id'].unique() for id in cp_data[cp_data['rs_id'] == rs_id]['id'].unique()]\n",
    "    n = len(tracks)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            rs_id_1, id_1 = tracks[i]\n",
    "            rs_id_2, id_2 = tracks[j]\n",
    "        \n",
    "            if rs_id_1 == rs_id_2:\n",
    "                continue\n",
    "        \n",
    "            track_1 = get_track(cp_data, rs_id_1, id_1)\n",
    "            track_2 = get_track(cp_data, rs_id_2, id_2)\n",
    "                    \n",
    "            track = merge_tracks(track_1, track_2, track_length, error, velocity, acceleration)\n",
    "            if track is None:\n",
    "                continue\n",
    "        \n",
    "            label = int(id_1 == id_2)\n",
    "            x_cur = torch.tensor(track.values, dtype=torch.float32).reshape((-1,)).unsqueeze(0)\n",
    "            y_cur = torch.tensor([label], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            x = torch.cat((x, x_cur), 0)\n",
    "            y = torch.cat((y, y_cur), 0)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f5a4aa-54d0-4c94-af95-dae665418f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tl_data_from_cp_data_dir(dir, track_length, error, velocity, acceleration):\n",
    "    row_length = 4 + int(error) * 3 + int(velocity) * 3 + int(acceleration) * 3\n",
    "    x, y = torch.empty((0, track_length * row_length)), torch.empty((0, 1))\n",
    "    files = get_csv_files_from_dir(dir)\n",
    "\n",
    "    for file in files:\n",
    "        print(f'- file {file} ', end='')\n",
    "        x_cur, y_cur = generate_tl_data_from_cp_data_file(file, track_length, error, velocity, acceleration)\n",
    "        print(f'({x_cur.shape[0]} rows)')\n",
    "        \n",
    "        x = torch.cat((x, x_cur), 0)\n",
    "        y = torch.cat((y, y_cur), 0)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32487e3-4262-43b3-82dc-61985be0918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_data_dir = 'CP_data'\n",
    "tl_data_dir = 'TL_data'\n",
    "\n",
    "track_length = 16\n",
    "\n",
    "error        = False\n",
    "velocity     = False\n",
    "acceleration = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6071cbbb-30fb-40d5-ac31-db36b97ac19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CP_data/train\n",
      "- file CP_data/train/50ao_25rs_xyz_quadratic.csv (1563 rows)\n",
      "- file CP_data/train/1ao_2rs_x-linear.csv (0 rows)\n",
      "Saving to TL_data/train (1563 rows)\n",
      "\n",
      "Processing CP_data/test\n",
      "- file CP_data/test/1ao_2rs.csv (0 rows)\n",
      "Nothing to save to TL_data/test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_usage_aim in ('train', 'test'):\n",
    "    print(f'Processing {cp_data_dir}/{data_usage_aim}')\n",
    "    \n",
    "    x, y = generate_tl_data_from_cp_data_dir(f'{cp_data_dir}/{data_usage_aim}', track_length, error, velocity, acceleration)\n",
    "    \n",
    "    if x.shape[0] != 0:\n",
    "        print(f'Saving to {tl_data_dir}/{data_usage_aim} ({x.shape[0]} rows)')\n",
    "        torch.save(x, f'{tl_data_dir}/{data_usage_aim}/x.pt')\n",
    "        torch.save(y, f'{tl_data_dir}/{data_usage_aim}/y.pt')\n",
    "    else:\n",
    "        print(f'Nothing to save to {tl_data_dir}/{data_usage_aim}')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a26b4-59cb-404f-bbd9-ab15ddab0211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
