{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322b01a5-63f4-42f2-bfb7-b34b62a4006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gv/4nk2tvfd4tjdhkr_hnd4tsz00000gn/T/ipykernel_86350/3714074986.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from airsim.collections import AirObject, AirEnv, RadarSystem, ControlPoint\n",
    "from airsim.time import Time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7706943a-ecfd-423e-90c4-4eb456ce7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(columns, suffix='_'):\n",
    "    return [f'{col}{suffix}' for col in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fa0ba5-a852-4318-bb2c-f018ba24b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, shuffle_train=False, dropna_train=True):\n",
    "        self.__shuffle_train = shuffle_train\n",
    "        self.__dropna_train = dropna_train\n",
    "        \n",
    "        self.__t_min = None\n",
    "        self.__t_max = None\n",
    "        self.__dt = None\n",
    "\n",
    "        self.__air_objects = None\n",
    "        self.__air_env = None\n",
    "        self.__radar_systems = None\n",
    "        self.__control_point = None\n",
    "\n",
    "    def __run_system(self, dropna=True):\n",
    "        t = Time()\n",
    "        t.set(self.__t_min)\n",
    "\n",
    "        progressbar = tqdm(range(int((self.__t_max - self.__t_min)/self.__dt)))\n",
    "        progressbar.set_description('Running system')\n",
    "        for i in progressbar:\n",
    "            for radar_system in self.__radar_systems:\n",
    "                radar_system.trigger()\n",
    "\n",
    "            if i == int((self.__t_max - self.__t_min)/self.__dt) - 1:\n",
    "                for radar_system in self.__radar_systems:\n",
    "                    radar_system.estimate_velocity()\n",
    "                    radar_system.estimate_acceleration()\n",
    "                self.__control_point.upload_data()\n",
    "            \n",
    "            t.step(self.__dt)\n",
    "\n",
    "    def __get_control_point_data(self):\n",
    "        data = self.__control_point.get_data()\n",
    "        if self.__dropna_train:\n",
    "            data = data.dropna()\n",
    "        return data\n",
    "\n",
    "    def __get_past_new_detections_cross_join_by_time(self, data, t):\n",
    "        detection_columns = ['time', 'x', 'y', 'z', 'x_err', 'y_err', 'z_err']\n",
    "        v_est_columns = [f'v_{axis}_est' for axis in ('x', 'y', 'z')]\n",
    "        a_est_columns = [f'a_{axis}_est' for axis in ('x', 'y', 'z')]\n",
    "    \n",
    "        suffix = '_'\n",
    "        cols = detection_columns + v_est_columns + a_est_columns\n",
    "        cols_new = add_suffix(detection_columns + v_est_columns + a_est_columns, suffix)\n",
    "        dfl = data.loc[data['time'] < t].copy()\n",
    "        dfl = dfl.sort_values(by=['id', 'time', 'err_ratio'], ascending=[True, False, False])\n",
    "        dfl = dfl.drop_duplicates(subset=['id', 'time'])\n",
    "        dfl = dfl.groupby(by=['id']).head(1)\n",
    "        dfl = dfl.rename(columns={cols[i]: cols_new[i] for i in range(len(cols))})\n",
    "        dfl = dfl[['id'] + cols_new]\n",
    "        dfl = dfl.reset_index(drop=True)\n",
    "        \n",
    "        dfr = data.loc[data['time'] == t].copy()\n",
    "        dfr = dfr.sort_values(by=['id', 'err_ratio'], ascending=[True, False])\n",
    "        dfr = dfr[['id'] + detection_columns]\n",
    "        dfr = dfr.reset_index(drop=True)\n",
    "    \n",
    "        df = pd.merge(dfl, dfr, how='cross')\n",
    "        df['is_identical'] = df['id_x'] == df['id_y']\n",
    "        df = df.astype({'is_identical': 'float64'})\n",
    "        df = df.drop(columns=['id_x', 'id_y'])\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def __get_past_new_detections_cross_join(self, data):\n",
    "        dfs = []\n",
    "        data['err_ratio'] = np.sqrt(3.0 / (data['x_err']**2 + data['y_err']**2 + data['z_err']**2))\n",
    "\n",
    "        timestamps = sorted(set(data['time']))[1:]\n",
    "        progressbar = tqdm(range(len(timestamps)))\n",
    "        progressbar.set_description('Generating input data')\n",
    "        for t_id in progressbar:\n",
    "            df_t = self.__get_past_new_detections_cross_join_by_time(data, timestamps[t_id])\n",
    "            dfs.append(df_t)\n",
    "    \n",
    "        df = pd.concat(dfs).reset_index(drop=True)\n",
    "        if self.__shuffle_train:\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def generate_1ao_2rs(self, ao_track, t_min, t_max, dt):\n",
    "        self.__t_min = t_min\n",
    "        self.__t_max = t_max\n",
    "        self.__dt = dt\n",
    "        \n",
    "        self.__air_objects = [AirObject(track=ao_track)]\n",
    "        self.__air_env = AirEnv(air_objects=self.__air_objects)\n",
    "        self.__radar_systems = [\n",
    "            RadarSystem(position=np.array([0, 0, 0]), detection_radius=10**10, error=0.1, air_env=self.__air_env),\n",
    "            RadarSystem(position=np.array([0, 0, 0]), detection_radius=10**10, error=0.1, air_env=self.__air_env)\n",
    "        ]\n",
    "        self.__control_point = ControlPoint(radar_systems=self.__radar_systems)\n",
    "\n",
    "        self.__run_system()\n",
    "        return self.__get_past_new_detections_cross_join(self.__get_control_point_data())\n",
    "\n",
    "    def generate_Nao_2rs(self, ao_tracks, t_min, t_max, dt):\n",
    "        self.__t_min = t_min\n",
    "        self.__t_max = t_max\n",
    "        self.__dt = dt\n",
    "        \n",
    "        self.__air_objects = [AirObject(track=ao_tracks[i]) for i in range(len(ao_tracks))]\n",
    "        self.__air_env = AirEnv(air_objects=self.__air_objects)\n",
    "        self.__radar_systems = [\n",
    "            RadarSystem(position=np.array([0, 0, 0]), detection_radius=10**10, error=0.1, air_env=self.__air_env),\n",
    "            RadarSystem(position=np.array([0, 0, 0]), detection_radius=10**10, error=0.1, air_env=self.__air_env)\n",
    "        ]\n",
    "        self.__control_point = ControlPoint(radar_systems=self.__radar_systems)\n",
    "\n",
    "        self.__run_system()\n",
    "        return self.__get_past_new_detections_cross_join(self.__get_control_point_data())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687b2a53-fbe8-415f-81cb-da15bf518342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6cd9c8-17d6-430f-ac90-42f902501569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088626e19b514cf4bff4e5985cb2eb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c611b892f3e4b65bfe3a9b73b1e8af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(t):\n",
    "    if t <= 15000:\n",
    "        return np.array([t, 0, 10000])\n",
    "    elif t <= 30000:\n",
    "        return np.array([30000 - t, 0, 10000])\n",
    "    elif t <= 45000:\n",
    "        return np.array([0.5 * (t - 30000), 0, 10000])\n",
    "    elif t <= 60000:\n",
    "        return np.array([15000 - 0.5 * (t - 30000), 0, 10000])\n",
    "\n",
    "df = dg.generate_1ao_2rs(ao_track=f, t_min=0, t_max=60000, dt=1)\n",
    "\n",
    "df.to_csv('data/1ao_2rs_f.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eae4418-08cb-4610-ab2d-5d79e613ac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69952bb4066a467d8cc293a21b4e65b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc713b014caf46098d1062df707b917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def g(t):\n",
    "    return np.array([0.7 * t, 0, 10000])\n",
    "\n",
    "df = dg.generate_1ao_2rs(ao_track=g, t_min=0, t_max=1000, dt=1)\n",
    "\n",
    "df.to_csv('data/1ao_2rs_g.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c819c3-a271-4df1-b4c0-24b5b311fdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec05911f804847a08f94c6575262d964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6785656c06464f6b9f24224bbf396fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(t):\n",
    "    return np.array([1.5 * t, 0, 10000])\n",
    "\n",
    "df = dg.generate_1ao_2rs(ao_track=h, t_min=0, t_max=1000, dt=1)\n",
    "\n",
    "df.to_csv('data/1ao_2rs_h.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
