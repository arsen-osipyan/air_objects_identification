{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322b01a5-63f4-42f2-bfb7-b34b62a4006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843b25ce-0191-45a8-b946-f84e9adcd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files_from_dir(dir):\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        f = os.path.join(dir, file)\n",
    "        if os.path.isfile(f) and f.endswith('.csv'):\n",
    "            files.append(f)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb7ac10-74c8-4026-8bab-f1c2e8cea57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cp_data(data, error, velocity, acceleration):\n",
    "    data = data.sort_values(by=['rs_id', 'id', 'time']).reset_index(drop=True)\n",
    "    \n",
    "    data = data[\n",
    "        ['rs_id', 'id', 'time', 'x', 'y', 'z'] + \\\n",
    "        (['x_err', 'y_err', 'z_err'] if error else []) + \\\n",
    "        (['v_x_est', 'v_y_est', 'v_z_est'] if velocity else []) + \\\n",
    "        (['a_x_est', 'a_y_est', 'a_z_est'] if acceleration else [])\n",
    "    ]\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064e04a7-cb4e-413f-9b77-352e5d9971e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track(data, rs_id, id, t_min=None, t_max=None, drop_ids=True):\n",
    "    track = data[(data['rs_id'] == rs_id) & (data['id'] == id)]\n",
    "    if t_min is not None:\n",
    "        track = track[track['time'] >= t_min]\n",
    "    if t_max is not None:\n",
    "        track = track[track['time'] <= t_max]\n",
    "    if drop_ids:\n",
    "        track = track.drop(columns=['rs_id', 'id'])\n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764a7870-5af0-45d6-80ff-7614dead328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_timeranges_intersection(track_1, track_2):\n",
    "    t_min_1, t_max_1 = track_1['time'].min(), track_1['time'].max()\n",
    "    t_min_2, t_max_2 = track_2['time'].min(), track_2['time'].max()\n",
    "\n",
    "    t_min, t_max = max(t_min_1, t_min_2), min(t_max_1, t_max_2)\n",
    "    return t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aaeba99-c2cf-49a8-8902-95de0f8287ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_track_with_zeros(track, track_length, zeros_placement='start'):\n",
    "    if track.size(0) == 0 or track_length == 0:\n",
    "        return None\n",
    "    if track.size(0) >= track_length:\n",
    "        return track[:track_length, :]\n",
    "    \n",
    "    zeros = torch.zeros(track_length - track.size(0), track.size(1))\n",
    "    \n",
    "    if zeros_placement == 'start':\n",
    "        return torch.cat((zeros, track), 0)\n",
    "    elif zeros_placement == 'end':\n",
    "        return torch.cat((track, zeros), 0)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474882bf-183a-4a97-ab79-bfc62240349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_track_with_linear_interpolation(track, track_length):\n",
    "    if track.size(0) < 2 or track_length == 0:\n",
    "        return None\n",
    "    if track.size(0) >= track_length:\n",
    "        return track[:track_length, :]\n",
    "\n",
    "    while track.size(0) != track_length:\n",
    "        diffs = track[:, 0].diff(1, 0)\n",
    "\n",
    "        point_1_idx = torch.argmax(diffs).item()\n",
    "        point_2_idx = point_1_idx + 1\n",
    "\n",
    "        new_point = torch.lerp(track[point_1_idx, :], track[point_2_idx, :], 0.5).unsqueeze(0)\n",
    "\n",
    "        track = torch.cat((track[:point_1_idx+1, :], new_point, track[point_2_idx:, :]), 0)\n",
    "\n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e621619b-19f8-464c-8579-a81ce0774855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_siamese_data_from_cp_tracks(track_1, track_2, track_length, drop_last=False):\n",
    "    if track_1.shape[1] != track_2.shape[1]:\n",
    "        raise RuntimeError(f'Tracks must have the same number of columns, got {track_1.shape[1]} and {track_2.shape[1]} instead.')\n",
    "    \n",
    "    x = torch.empty((0, 2, track_1.shape[1], track_length))\n",
    "    \n",
    "    t_min, t_max = get_tracks_timeranges_intersection(track_1, track_2)\n",
    "    \n",
    "    current_t_max = t_max\n",
    "\n",
    "    break_flag = False\n",
    "    while current_t_max > t_min:\n",
    "        # crop tracks to current max time\n",
    "        track_1 = track_1[track_1['time'] < current_t_max]\n",
    "        track_2 = track_2[track_2['time'] < current_t_max]\n",
    "\n",
    "        # get last parts of tracks\n",
    "        track_1_part = track_1.tail(track_length)\n",
    "        track_2_part = track_2.tail(track_length)\n",
    "\n",
    "        # remove last parts of tracks from original tracks\n",
    "        track_1 = track_1.drop(track_1.tail(track_length).index)\n",
    "        track_2 = track_2.drop(track_2.tail(track_length).index)\n",
    "\n",
    "        # transform to tensors\n",
    "        track_1_part_tensor = torch.tensor(track_1_part.values, dtype=torch.float32)\n",
    "        track_2_part_tensor = torch.tensor(track_2_part.values, dtype=torch.float32)\n",
    " \n",
    "        if track_1_part_tensor.size(0) < track_length:\n",
    "            if drop_last:\n",
    "                break\n",
    "            # track_1_part_tensor = extend_track_with_zeros(track_1_part_tensor, track_length)\n",
    "            track_1_part_tensor = extend_track_with_linear_interpolation(track_1_part_tensor, track_length)\n",
    "            if track_1_part_tensor is None:\n",
    "                break\n",
    "            break_flag = True\n",
    "\n",
    "        if track_2_part_tensor.size(0) < track_length:\n",
    "            if drop_last:\n",
    "                break\n",
    "            # track_2_part_tensor = extend_track_with_zeros(track_2_part_tensor, track_length)\n",
    "            track_2_part_tensor = extend_track_with_linear_interpolation(track_2_part_tensor, track_length)\n",
    "            if track_2_part_tensor is None:\n",
    "                break\n",
    "            break_flag = True\n",
    "\n",
    "        track_1_part_tensor = track_1_part_tensor.transpose(0, 1).unsqueeze(0)\n",
    "        track_2_part_tensor = track_2_part_tensor.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "        x = torch.cat((x, torch.cat((track_1_part_tensor, track_2_part_tensor), 0).unsqueeze(0)))\n",
    "        \n",
    "        if break_flag:\n",
    "            break\n",
    "\n",
    "        current_t_max = min(track_1['time'].max(), track_2['time'].max())\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef8ca1d-322c-4952-b8a4-cbbac4fc4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_siamese_data_from_cp_data_file(file, track_length, error, velocity, acceleration):\n",
    "    row_length = 4 + int(error) * 3 + int(velocity) * 3 + int(acceleration) * 3\n",
    "    x, y = torch.empty((0, 2, row_length, track_length)), torch.empty((0, 1))\n",
    "    \n",
    "    cp_data = pd.read_csv(file)\n",
    "    cp_data = transform_cp_data(cp_data, error, velocity, acceleration)\n",
    "    \n",
    "    track_ids = [(rs_id, id) for rs_id in cp_data['rs_id'].unique() for id in cp_data[cp_data['rs_id'] == rs_id]['id'].unique()]\n",
    "    n = len(track_ids)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            rs_id_1, id_1 = track_ids[i]\n",
    "            rs_id_2, id_2 = track_ids[j]\n",
    "        \n",
    "            if rs_id_1 == rs_id_2:\n",
    "                continue\n",
    "\n",
    "            track_1 = get_track(cp_data, rs_id_1, id_1)\n",
    "            track_2 = get_track(cp_data, rs_id_2, id_2)\n",
    "\n",
    "            x_cur = generate_siamese_data_from_cp_tracks(track_1, track_2, track_length, drop_last=False)\n",
    "            y_cur = torch.zeros(x_cur.size(0), 1) if id_1 == id_2 else torch.ones(x_cur.size(0), 1)\n",
    "\n",
    "            x = torch.cat((x, x_cur), 0)\n",
    "            y = torch.cat((y, y_cur), 0)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f5a4aa-54d0-4c94-af95-dae665418f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_siamese_data_from_cp_data_dir(dir, track_length, error, velocity, acceleration):\n",
    "    row_length = 4 + int(error) * 3 + int(velocity) * 3 + int(acceleration) * 3\n",
    "    x, y = torch.empty((0, 2, row_length, track_length)), torch.empty((0, 1))\n",
    "    \n",
    "    for file in get_csv_files_from_dir(dir):\n",
    "        x_cur, y_cur = generate_siamese_data_from_cp_data_file(file, track_length, error, velocity, acceleration)\n",
    "        print(f'- file {file} ({x_cur.size(0)} rows)')\n",
    "        \n",
    "        x = torch.cat((x, x_cur), 0)\n",
    "        y = torch.cat((y, y_cur), 0)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32487e3-4262-43b3-82dc-61985be0918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_data_dir      = 'CP_data'\n",
    "siamese_data_dir = 'siamese_data'\n",
    "\n",
    "timestamp        = False\n",
    "\n",
    "track_length     = 32\n",
    "error            = False\n",
    "velocity         = False\n",
    "acceleration     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6071cbbb-30fb-40d5-ac31-db36b97ac19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP_data/train\n",
      "- file CP_data/train/data_0604202101.csv (860 rows)\n",
      "- file CP_data/train/data_0604204202.csv (864 rows)\n",
      "- file CP_data/train/data_0604221519.csv (864 rows)\n",
      "- file CP_data/train/data_0604220607.csv (860 rows)\n",
      "- file CP_data/train/data_0604211343.csv (860 rows)\n",
      "- file CP_data/train/data_0604204028.csv (860 rows)\n",
      "- file CP_data/train/data_0604203021.csv (860 rows)\n",
      "- file CP_data/train/data_0604222825.csv (860 rows)\n",
      "- file CP_data/train/data_0604203155.csv (864 rows)\n",
      "- file CP_data/train/data_0604202539.csv (860 rows)\n",
      "- file CP_data/train/data_0604202934.csv (864 rows)\n",
      "- file CP_data/train/data_0604200851.csv (860 rows)\n",
      "- file CP_data/train/data_0604215521.csv (864 rows)\n",
      "- file CP_data/train/data_0604212514.csv (864 rows)\n",
      "- file CP_data/train/data_0604215044.csv (860 rows)\n",
      "- file CP_data/train/data_0604220000.csv (864 rows)\n",
      "- file CP_data/train/data_0604215130.csv (860 rows)\n",
      "- file CP_data/train/data_0604203550.csv (860 rows)\n",
      "- file CP_data/train/data_0604215913.csv (860 rows)\n",
      "- file CP_data/train/data_0604213345.csv (864 rows)\n",
      "- file CP_data/train/data_0604220957.csv (864 rows)\n",
      "- file CP_data/train/data_0604202711.csv (860 rows)\n",
      "- file CP_data/train/data_0604201542.csv (860 rows)\n",
      "- file CP_data/train/data_0604205730.csv (864 rows)\n",
      "- file CP_data/train/data_0604221651.csv (860 rows)\n",
      "- file CP_data/train/data_0604214826.csv (856 rows)\n",
      "- file CP_data/train/data_0604200502.csv (860 rows)\n",
      "- file CP_data/train/data_0604215655.csv (864 rows)\n",
      "- file CP_data/train/data_0604205644.csv (860 rows)\n",
      "- file CP_data/train/data_0604221043.csv (860 rows)\n",
      "- file CP_data/train/data_0604220349.csv (864 rows)\n",
      "- file CP_data/train/data_0604222214.csv (860 rows)\n",
      "- file CP_data/train/data_0604200937.csv (864 rows)\n",
      "- file CP_data/train/data_0604202846.csv (864 rows)\n",
      "- file CP_data/train/data_0604204947.csv (860 rows)\n",
      "- file CP_data/train/data_0604195758.csv (856 rows)\n",
      "- file CP_data/train/data_0604222957.csv (860 rows)\n",
      "- file CP_data/train/data_0604200103.csv (864 rows)\n",
      "- file CP_data/train/data_0604223043.csv (864 rows)\n",
      "- file CP_data/train/data_0604195407.csv (864 rows)\n",
      "- file CP_data/train/data_0604201023.csv (860 rows)\n",
      "- file CP_data/train/data_0604210648.csv (860 rows)\n",
      "- file CP_data/train/data_0604214214.csv (864 rows)\n",
      "- file CP_data/train/data_0604210516.csv (864 rows)\n",
      "- file CP_data/train/data_0604221736.csv (864 rows)\n",
      "- file CP_data/train/data_0604221911.csv (860 rows)\n",
      "- file CP_data/train/data_0604201627.csv (860 rows)\n",
      "- file CP_data/train/data_0604195149.csv (860 rows)\n",
      "- file CP_data/train/data_0604203636.csv (864 rows)\n",
      "- file CP_data/train/data_0604213431.csv (860 rows)\n",
      "- file CP_data/train/data_0604205904.csv (856 rows)\n",
      "- file CP_data/train/data_0604214606.csv (864 rows)\n",
      "- file CP_data/train/data_0604205252.csv (860 rows)\n",
      "- file CP_data/train/data_0604222606.csv (860 rows)\n",
      "- file CP_data/train/data_0604220824.csv (860 rows)\n",
      "- file CP_data/train/data_0604201154.csv (860 rows)\n",
      "- file CP_data/train/data_0604205118.csv (864 rows)\n",
      "- file CP_data/train/data_0604213735.csv (860 rows)\n",
      "- file CP_data/train/data_0604201325.csv (860 rows)\n",
      "- file CP_data/train/data_0604204507.csv (860 rows)\n",
      "- file CP_data/train/data_0604202406.csv (864 rows)\n",
      "- file CP_data/train/data_0604220738.csv (860 rows)\n",
      "- file CP_data/train/data_0604202016.csv (856 rows)\n",
      "- file CP_data/train/data_0604213126.csv (864 rows)\n",
      "- file CP_data/train/data_0604200416.csv (860 rows)\n",
      "- file CP_data/train/data_0604215741.csv (864 rows)\n",
      "- file CP_data/train/data_0604221433.csv (860 rows)\n",
      "- file CP_data/train/data_0604212600.csv (860 rows)\n",
      "- file CP_data/train/data_0604215609.csv (860 rows)\n",
      "- file CP_data/train/data_0604204248.csv (864 rows)\n",
      "- file CP_data/train/data_0604201456.csv (860 rows)\n",
      "- file CP_data/train/data_0604205817.csv (860 rows)\n",
      "- file CP_data/train/data_0604195931.csv (864 rows)\n",
      "- file CP_data/train/data_0604200548.csv (860 rows)\n",
      "- file CP_data/train/data_0604210820.csv (860 rows)\n",
      "- file CP_data/train/data_0604195845.csv (860 rows)\n",
      "- file CP_data/train/data_0604211257.csv (860 rows)\n",
      "- file CP_data/train/data_0604212212.csv (864 rows)\n",
      "- file CP_data/train/data_0604203108.csv (860 rows)\n",
      "- file CP_data/train/data_0604204115.csv (860 rows)\n",
      "- file CP_data/train/data_0604212039.csv (864 rows)\n",
      "- file CP_data/train/data_0604205425.csv (864 rows)\n",
      "- file CP_data/train/data_0604203242.csv (864 rows)\n",
      "- file CP_data/train/data_0604212429.csv (860 rows)\n",
      "- file CP_data/train/data_0604215434.csv (864 rows)\n",
      "- file CP_data/train/data_0604211124.csv (860 rows)\n",
      "- file CP_data/train/data_0604212820.csv (860 rows)\n",
      "- file CP_data/train/data_0604203722.csv (860 rows)\n",
      "- file CP_data/train/data_0604212954.csv (860 rows)\n",
      "- file CP_data/train/data_0604210603.csv (864 rows)\n",
      "- file CP_data/train/data_0604221347.csv (860 rows)\n",
      "- file CP_data/train/data_0604222128.csv (860 rows)\n",
      "- file CP_data/train/data_0604201108.csv (864 rows)\n",
      "- file CP_data/train/data_0604195712.csv (860 rows)\n",
      "- file CP_data/train/data_0604213040.csv (864 rows)\n",
      "- file CP_data/train/data_0604214739.csv (864 rows)\n",
      "- file CP_data/train/data_0604210952.csv (856 rows)\n",
      "- file CP_data/train/data_0604214301.csv (864 rows)\n",
      "- file CP_data/train/data_0604211735.csv (860 rows)\n",
      "- file CP_data/train/data_0604201240.csv (864 rows)\n",
      "- file CP_data/train/data_0604213650.csv (864 rows)\n",
      "- file CP_data/train/data_0604205032.csv (860 rows)\n",
      "- file CP_data/train/data_0604203330.csv (860 rows)\n",
      "- file CP_data/train/data_0604222301.csv (864 rows)\n",
      "- file CP_data/train/data_0604205557.csv (860 rows)\n",
      "- file CP_data/train/data_0604195103.csv (860 rows)\n",
      "- file CP_data/train/data_0604222739.csv (864 rows)\n",
      "- file CP_data/train/data_0604210210.csv (860 rows)\n",
      "- file CP_data/train/data_0604200017.csv (864 rows)\n",
      "- file CP_data/train/data_0604220304.csv (864 rows)\n",
      "- file CP_data/train/data_0604214912.csv (860 rows)\n",
      "- file CP_data/train/data_0604221956.csv (860 rows)\n",
      "- file CP_data/train/data_0604221215.csv (864 rows)\n",
      "- file CP_data/train/data_0604210037.csv (864 rows)\n",
      "- file CP_data/train/data_0604213258.csv (864 rows)\n",
      "- file CP_data/train/data_0604221605.csv (860 rows)\n",
      "- file CP_data/train/data_0604200634.csv (860 rows)\n",
      "- file CP_data/train/data_0604214127.csv (864 rows)\n",
      "- file CP_data/train/data_0604204334.csv (864 rows)\n",
      "- file CP_data/train/data_0604221823.csv (860 rows)\n",
      "- file CP_data/train/data_0604200806.csv (860 rows)\n",
      "- file CP_data/train/data_0604213517.csv (860 rows)\n",
      "- file CP_data/train/data_0604215827.csv (864 rows)\n",
      "- file CP_data/train/data_0604202624.csv (856 rows)\n",
      "- file CP_data/train/data_0604204900.csv (860 rows)\n",
      "- file CP_data/train/data_0604220652.csv (860 rows)\n",
      "- file CP_data/train/data_0604201844.csv (860 rows)\n",
      "- file CP_data/train/data_0604204727.csv (860 rows)\n",
      "- file CP_data/train/data_0604201930.csv (860 rows)\n",
      "- file CP_data/train/data_0604203855.csv (860 rows)\n",
      "- file CP_data/train/data_0604200151.csv (860 rows)\n",
      "- file CP_data/train/data_0604210430.csv (864 rows)\n",
      "- file CP_data/train/data_0604210343.csv (860 rows)\n",
      "- file CP_data/train/data_0604195454.csv (864 rows)\n",
      "- file CP_data/train/data_0604211908.csv (860 rows)\n",
      "- file CP_data/train/data_0604214521.csv (860 rows)\n",
      "- file CP_data/train/data_0604222911.csv (864 rows)\n",
      "- file CP_data/train/data_0604202800.csv (864 rows)\n",
      "- file CP_data/train/data_0604214041.csv (864 rows)\n",
      "- file CP_data/train/data_0604220045.csv (864 rows)\n",
      "- file CP_data/train/data_0604202233.csv (860 rows)\n",
      "- file CP_data/train/data_0604205951.csv (864 rows)\n",
      "- file CP_data/train/data_0604220521.csv (860 rows)\n",
      "- file CP_data/train/data_0604214653.csv (860 rows)\n",
      "- file CP_data/train/data_0604215216.csv (860 rows)\n",
      "- file CP_data/train/data_0604220911.csv (860 rows)\n",
      "- file CP_data/train/data_0604201713.csv (860 rows)\n",
      "- file CP_data/train/data_0604222653.csv (860 rows)\n",
      "- file CP_data/train/data_0604200237.csv (860 rows)\n",
      "- file CP_data/train/data_0604212343.csv (864 rows)\n",
      "- file CP_data/train/data_0604213908.csv (864 rows)\n",
      "- file CP_data/train/data_0604222519.csv (864 rows)\n",
      "- file CP_data/train/data_0604215348.csv (864 rows)\n",
      "- file CP_data/train/data_0604220132.csv (856 rows)\n",
      "- file CP_data/train/data_0604205205.csv (864 rows)\n",
      "- file CP_data/train/data_0604211516.csv (860 rows)\n",
      "- file CP_data/train/data_0604195321.csv (860 rows)\n",
      "- file CP_data/train/data_0604204640.csv (856 rows)\n",
      "- file CP_data/train/data_0604222042.csv (860 rows)\n",
      "- file CP_data/train/data_0604203503.csv (860 rows)\n",
      "- file CP_data/train/data_0604211649.csv (864 rows)\n",
      "- file CP_data/train/data_0604202147.csv (860 rows)\n",
      "- file CP_data/train/data_0604211821.csv (860 rows)\n",
      "- file CP_data/train/data_0604195541.csv (860 rows)\n",
      "- file CP_data/train/data_0604204814.csv (864 rows)\n",
      "- file CP_data/train/data_0604205511.csv (860 rows)\n",
      "- file CP_data/train/data_0604222347.csv (860 rows)\n",
      "- file CP_data/train/data_0604213603.csv (860 rows)\n",
      "- file CP_data/train/data_0604211954.csv (860 rows)\n",
      "- file CP_data/train/data_0604221129.csv (864 rows)\n",
      "- file CP_data/train/data_0604214347.csv (864 rows)\n",
      "- file CP_data/train/data_0604200326.csv (860 rows)\n",
      "- file CP_data/train/data_0604203808.csv (860 rows)\n",
      "- file CP_data/train/data_0604213212.csv (864 rows)\n",
      "- file CP_data/train/data_0604195018.csv (860 rows)\n",
      "- file CP_data/train/data_0604210257.csv (856 rows)\n",
      "- file CP_data/train/data_0604214958.csv (860 rows)\n",
      "- file CP_data/train/data_0604200720.csv (860 rows)\n",
      "- file CP_data/train/data_0604203942.csv (860 rows)\n",
      "- file CP_data/train/data_0604212126.csv (860 rows)\n",
      "- file CP_data/train/data_0604221301.csv (864 rows)\n",
      "- file CP_data/train/data_0604212907.csv (864 rows)\n",
      "- file CP_data/train/data_0604210123.csv (856 rows)\n",
      "- file CP_data/train/data_0604202320.csv (864 rows)\n",
      "- file CP_data/train/data_0604202452.csv (860 rows)\n",
      "- file CP_data/train/data_0604204553.csv (860 rows)\n",
      "- file CP_data/train/data_0604195235.csv (860 rows)\n",
      "- file CP_data/train/data_0604201759.csv (860 rows)\n",
      "- file CP_data/train/data_0604222433.csv (860 rows)\n",
      "- file CP_data/train/data_0604213822.csv (864 rows)\n",
      "- file CP_data/train/data_0604220218.csv (864 rows)\n",
      "- file CP_data/train/data_0604203417.csv (860 rows)\n",
      "- file CP_data/train/data_0604211211.csv (864 rows)\n",
      "- file CP_data/train/data_0604214433.csv (864 rows)\n",
      "- file CP_data/train/data_0604210735.csv (864 rows)\n",
      "- file CP_data/train/data_0604205338.csv (860 rows)\n",
      "- file CP_data/train/data_0604210906.csv (860 rows)\n",
      "- file CP_data/train/data_0604213955.csv (860 rows)\n",
      "- file CP_data/train/data_0604220435.csv (860 rows)\n",
      "- file CP_data/train/data_0604212646.csv (860 rows)\n",
      "- file CP_data/train/data_0604211429.csv (860 rows)\n",
      "- file CP_data/train/data_0604204420.csv (864 rows)\n",
      "- file CP_data/train/data_0604212257.csv (860 rows)\n",
      "- file CP_data/train/data_0604211038.csv (860 rows)\n",
      "- file CP_data/train/data_0604212733.csv (864 rows)\n",
      "- file CP_data/train/data_0604195627.csv (860 rows)\n",
      "- file CP_data/train/data_0604215302.csv (864 rows)\n",
      "- file CP_data/train/data_0604201411.csv (860 rows)\n",
      "- file CP_data/train/data_0604211602.csv (860 rows)\n",
      "- file CP_data/train/data_0604223129.csv (860 rows)\n",
      "Saving to siamese_data/train (180872 rows).\n",
      "\n",
      "CP_data/test\n",
      "- file CP_data/test/data_0604223520.csv (144 rows)\n",
      "- file CP_data/test/data_0604223441.csv (144 rows)\n",
      "- file CP_data/test/data_0604223655.csv (144 rows)\n",
      "- file CP_data/test/data_0604223735.csv (144 rows)\n",
      "- file CP_data/test/data_0604223536.csv (144 rows)\n",
      "- file CP_data/test/data_0604223250.csv (144 rows)\n",
      "- file CP_data/test/data_0604223456.csv (144 rows)\n",
      "- file CP_data/test/data_0604223917.csv (144 rows)\n",
      "- file CP_data/test/data_0604223719.csv (144 rows)\n",
      "- file CP_data/test/data_0604223321.csv (144 rows)\n",
      "- file CP_data/test/data_0604223137.csv (144 rows)\n",
      "- file CP_data/test/data_0604223647.csv (144 rows)\n",
      "- file CP_data/test/data_0604223727.csv (144 rows)\n",
      "- file CP_data/test/data_0604223901.csv (144 rows)\n",
      "- file CP_data/test/data_0604223242.csv (144 rows)\n",
      "- file CP_data/test/data_0604223153.csv (144 rows)\n",
      "- file CP_data/test/data_0604223806.csv (144 rows)\n",
      "- file CP_data/test/data_0604223345.csv (144 rows)\n",
      "- file CP_data/test/data_0604224013.csv (144 rows)\n",
      "- file CP_data/test/data_0604223226.csv (144 rows)\n",
      "- file CP_data/test/data_0604224005.csv (144 rows)\n",
      "- file CP_data/test/data_0604223743.csv (144 rows)\n",
      "- file CP_data/test/data_0604223409.csv (144 rows)\n",
      "- file CP_data/test/data_0604223353.csv (144 rows)\n",
      "- file CP_data/test/data_0604223623.csv (144 rows)\n",
      "- file CP_data/test/data_0604223145.csv (144 rows)\n",
      "- file CP_data/test/data_0604223814.csv (144 rows)\n",
      "- file CP_data/test/data_0604223425.csv (144 rows)\n",
      "- file CP_data/test/data_0604223949.csv (144 rows)\n",
      "- file CP_data/test/data_0604224029.csv (144 rows)\n",
      "- file CP_data/test/data_0604223544.csv (144 rows)\n",
      "- file CP_data/test/data_0604223234.csv (144 rows)\n",
      "- file CP_data/test/data_0604223552.csv (144 rows)\n",
      "- file CP_data/test/data_0604223751.csv (144 rows)\n",
      "- file CP_data/test/data_0604223209.csv (144 rows)\n",
      "- file CP_data/test/data_0604223433.csv (144 rows)\n",
      "- file CP_data/test/data_0604223631.csv (144 rows)\n",
      "- file CP_data/test/data_0604223600.csv (144 rows)\n",
      "- file CP_data/test/data_0604223417.csv (144 rows)\n",
      "- file CP_data/test/data_0604223615.csv (144 rows)\n",
      "- file CP_data/test/data_0604223830.csv (144 rows)\n",
      "- file CP_data/test/data_0604223401.csv (144 rows)\n",
      "- file CP_data/test/data_0604224021.csv (144 rows)\n",
      "- file CP_data/test/data_0604223941.csv (144 rows)\n",
      "- file CP_data/test/data_0604223217.csv (144 rows)\n",
      "- file CP_data/test/data_0604223607.csv (144 rows)\n",
      "- file CP_data/test/data_0604223639.csv (144 rows)\n",
      "- file CP_data/test/data_0604223822.csv (144 rows)\n",
      "- file CP_data/test/data_0604223201.csv (144 rows)\n",
      "- file CP_data/test/data_0604223957.csv (144 rows)\n",
      "- file CP_data/test/data_0604223758.csv (144 rows)\n",
      "- file CP_data/test/data_0604224037.csv (144 rows)\n",
      "- file CP_data/test/data_0604223837.csv (144 rows)\n",
      "- file CP_data/test/data_0604223449.csv (148 rows)\n",
      "- file CP_data/test/data_0604223703.csv (144 rows)\n",
      "- file CP_data/test/data_0604224044.csv (144 rows)\n",
      "- file CP_data/test/data_0604223925.csv (144 rows)\n",
      "- file CP_data/test/data_0604223528.csv (144 rows)\n",
      "- file CP_data/test/data_0604223306.csv (144 rows)\n",
      "- file CP_data/test/data_0604223845.csv (144 rows)\n",
      "- file CP_data/test/data_0604223853.csv (144 rows)\n",
      "- file CP_data/test/data_0604223338.csv (144 rows)\n",
      "- file CP_data/test/data_0604223258.csv (144 rows)\n",
      "- file CP_data/test/data_0604223933.csv (144 rows)\n",
      "- file CP_data/test/data_0604223329.csv (144 rows)\n",
      "- file CP_data/test/data_0604223711.csv (144 rows)\n",
      "- file CP_data/test/data_0604223512.csv (144 rows)\n",
      "- file CP_data/test/data_0604223314.csv (144 rows)\n",
      "- file CP_data/test/data_0604223504.csv (144 rows)\n",
      "- file CP_data/test/data_0604223909.csv (144 rows)\n",
      "Saving to siamese_data/test (10084 rows).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for data_usage_aim in ('test',):\n",
    "# for data_usage_aim in ('train',):\n",
    "for data_usage_aim in ('train', 'test'):\n",
    "    print(f'{cp_data_dir}/{data_usage_aim}')\n",
    "    x, y = generate_siamese_data_from_cp_data_dir(f'{cp_data_dir}/{data_usage_aim}', track_length, error, velocity, acceleration)\n",
    "\n",
    "    if x.size(0) != 0:\n",
    "        print(f'Saving to {siamese_data_dir}/{data_usage_aim} ({x.size(0)} rows).')\n",
    "\n",
    "        if timestamp:\n",
    "            ts = datetime.datetime.now().strftime('%d%m%H%M%S')\n",
    "            torch.save(x, f'{siamese_data_dir}/{data_usage_aim}/x_{ts}.pt')\n",
    "            torch.save(y, f'{siamese_data_dir}/{data_usage_aim}/y_{ts}.pt')\n",
    "        else:\n",
    "            torch.save(x, f'{siamese_data_dir}/{data_usage_aim}/x.pt')\n",
    "            torch.save(y, f'{siamese_data_dir}/{data_usage_aim}/y.pt')\n",
    "    else:\n",
    "        print(f'Nothing to save.')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceff0dd-f030-4cb4-83f1-acab8f35a2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
